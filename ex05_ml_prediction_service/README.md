# Exercice 05 â€“ Machine Learning & MLOps (Spark MLlib)

## Objectif

L'exercice **EX05** s'inscrit dans la continuitÃ© du pipeline Big Data mis en place dans les exercices prÃ©cÃ©dents (EX01 Ã  EX04). Son objectif est d'introduire une premiÃ¨re dÃ©marche **MLOps**, en implÃ©mentant un modÃ¨le de machine learning distribuÃ© Ã  l'aide de **Spark MLlib**, depuis la lecture des donnÃ©es jusqu'Ã  l'infÃ©rence.

### Objectifs principaux

- âœ… EntraÃ®ner un modÃ¨le ML Ã  partir de donnÃ©es stockÃ©es dans MinIO
- âœ… PrÃ©dire le montant total payÃ© (`total_amount`) pour une course de taxi
- âœ… Ã‰valuer la qualitÃ© du modÃ¨le avec des mÃ©triques standards
- âœ… Garantir la qualitÃ© logicielle (PEP8, tests unitaires, documentation)
- âœ… PrÃ©parer une architecture compatible avec des Ã©volutions MLOps futures
- âœ… **FenÃªtre glissante** pour entraÃ®nement mensuel automatisÃ©
- âœ… **Model Registry** avec promotion automatique des modÃ¨les

---

## ğŸ†• StratÃ©gie ML v2 - FenÃªtre Glissante

### Principe

Le pipeline ML utilise une **stratÃ©gie de fenÃªtre glissante** compatible avec une orchestration Airflow mensuelle :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FENÃŠTRE GLISSANTE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   Training Window (3 mois)          Test (1 mois)           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚   â”‚ M-3   â”‚ M-2   â”‚ M-1   â”‚    â†’    â”‚   M   â”‚               â”‚
â”‚   â”‚ Mars  â”‚ Avril â”‚ Mai   â”‚         â”‚ Juin  â”‚               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RÃ¨gle de Promotion

Le nouveau modÃ¨le (candidate) est promu si **au moins 2 mÃ©triques sur 3 s'amÃ©liorent** :

| MÃ©trique | Direction d'amÃ©lioration |
|----------|--------------------------|
| RMSE     | â†“ Plus bas = meilleur    |
| MAE      | â†“ Plus bas = meilleur    |
| RÂ²       | â†‘ Plus haut = meilleur   |

### Model Registry

Structure simple avec 2 slots maximum :

```
models/registry/
â”œâ”€â”€ model_registry.json     # MÃ©tadonnÃ©es et historique
â”œâ”€â”€ current/                # ModÃ¨le en production
â”‚   â”œâ”€â”€ metadata/
â”‚   â””â”€â”€ stages/
â””â”€â”€ candidate/              # Nouveau modÃ¨le Ã  Ã©valuer
    â”œâ”€â”€ metadata/
    â””â”€â”€ stages/
```

### ExÃ©cution Mensuelle (Airflow)

```bash
# Auto-dÃ©tection du mois courant
python src/ml_pipeline.py

# Appel avec mois de test explicite
python src/ml_pipeline.py --test-month 2023-06

# Appel avec mois d'entraÃ®nement explicites
python src/ml_pipeline.py \
    --train-months 2023-03,2023-04,2023-05 \
    --test-month 2023-06 \
    --model-registry-path models/registry
```

### Arguments CLI

| Argument               | Description                                      | Requis |
|------------------------|--------------------------------------------------|--------|
| `--test-month`         | Mois de test (ex: 2023-06). Si omis, utilise le mois courant | âŒ |
| `--train-months`       | Mois d'entraÃ®nement (ex: 2023-03,2023-04,2023-05)| âŒ     |
| `--model-registry-path`| Chemin du registry (dÃ©faut: models/registry)     | âŒ     |
| `--data-base-path`     | Chemin donnÃ©es MinIO (dÃ©faut: s3a://nyc-interim/yellow) | âŒ |
| `--reports-dir`        | RÃ©pertoire rapports (dÃ©faut: reports)            | âŒ     |
| `--dry-run`            | Validation des donnÃ©es sans exÃ©cution du training | âŒ    |
| `--skip-missing`       | Continue avec les donnÃ©es disponibles si certains mois manquent | âŒ |

### Gestion des donnÃ©es manquantes

Le pipeline valide automatiquement la disponibilitÃ© des donnÃ©es avant l'entraÃ®nement.

#### RÃ¨gles de validation

| Condition | RÃ©sultat |
|-----------|----------|
| Mois de **test** manquant | âŒ **ERREUR** (toujours obligatoire) |
| < 2 mois de **training** disponibles | âŒ **ERREUR** (minimum requis) |
| â‰¥ 2 mois de **training** disponibles | âœ… Continue |

#### Mode strict (par dÃ©faut)

```bash
python src/ml_pipeline.py --test-month 2023-06
```
â†’ Si **n'importe quel mois** manque â†’ **ERREUR** avec message explicite

#### Mode tolÃ©rant (`--skip-missing`)

```bash
python src/ml_pipeline.py --test-month 2023-06 --skip-missing
```
â†’ Continue avec les donnÃ©es disponibles SI :
- âœ… Le mois de test existe
- âœ… Au moins 2 mois de training existent

#### Exemple de message d'erreur

```
âŒ DATA NOT FOUND
==================================================
Missing months: ['2023/03', '2023/04']
Available months: ['2023/01', '2023/02', '2023/05']

Options:
  1. Ingest the missing data first
  2. Use --skip-missing to continue with available data
     (requires at least 2 training months + test month)
  3. Use --test-month to specify a different month
```

---

## Architecture

```
MinIO (nyc-interim)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Spark DataFrame      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Feature Engineering   â”‚
â”‚   (features.py)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Pipeline ML Spark     â”‚
â”‚   (StringIndexer +      â”‚
â”‚    OneHotEncoder +      â”‚
â”‚    VectorAssembler +    â”‚
â”‚    GBTRegressor)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
       â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
       â”‚         â”‚
       â–¼         â–¼
   Training   Inference
       â”‚         â”‚
       â–¼         â–¼
   Metrics    Predictions
   (reports/) (reports/)
```

### Composants

| Composant       | Description                          |
|-----------------|--------------------------------------|
| Spark Cluster   | 1 Master + 2 Workers (Docker)        |
| Data Lake       | MinIO (S3 compatible)                |
| ML Framework    | Spark MLlib                          |
| Langage         | Python (scripts uniquement)          |

---

## Structure du projet

```
ex05_ml_prediction_service/
â”œâ”€â”€ main.py                      # Point d'entrÃ©e principal
â”œâ”€â”€ pyproject.toml               # Configuration projet Python
â”œâ”€â”€ run_pipeline.ps1             # Orchestrateur principal (legacy + sliding window)
â”œâ”€â”€ run_tests_pre_train.ps1      # Tests avant entraÃ®nement
â”œâ”€â”€ run_ex05.ps1                 # EntraÃ®nement seul (legacy)
â”œâ”€â”€ run_tests_post_train.ps1     # Tests qualitÃ© aprÃ¨s entraÃ®nement
â”œâ”€â”€ run_predict.ps1              # InfÃ©rence seule
â”œâ”€â”€ run_tests_post_predict.ps1   # Tests plausibilitÃ© mÃ©tier
â”œâ”€â”€ conf/
â”‚   â””â”€â”€ log4j2.properties        # Configuration logging Spark
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ ex05_spark_model/        # ModÃ¨le entraÃ®nÃ© (legacy)
â”‚   â””â”€â”€ registry/                # Model Registry (sliding window)
â”‚       â”œâ”€â”€ model_registry.json  # MÃ©tadonnÃ©es & historique
â”‚       â”œâ”€â”€ current/             # ModÃ¨le en production
â”‚       â””â”€â”€ candidate/           # Nouveau modÃ¨le candidat
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ eda_sample.csv           # Ã‰chantillon EDA
â”‚   â”œâ”€â”€ eda_summary.json         # RÃ©sumÃ© statistique
â”‚   â”œâ”€â”€ error_summary.json       # Analyse d'erreurs globale
â”‚   â”œâ”€â”€ error_by_price_bucket.json # Erreurs par tranche de prix
â”‚   â”œâ”€â”€ predict_report.json      # Rapport d'infÃ©rence
â”‚   â””â”€â”€ train_metrics.json       # MÃ©triques d'entraÃ®nement
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py           # Configuration centralisÃ©e
â”‚   â”œâ”€â”€ eda.py              # Exploration des donnÃ©es
â”‚   â”œâ”€â”€ error_analysis.py   # Analyse d'erreurs post-prÃ©diction
â”‚   â”œâ”€â”€ features.py         # Feature engineering
â”‚   â”œâ”€â”€ logging_config.py   # Configuration logging centralisÃ©e âœ¨
â”‚   â”œâ”€â”€ ml_pipeline.py      # Pipeline ML orchestrable (sliding window)
â”‚   â”œâ”€â”€ model_registry.py   # Gestion du model registry
â”‚   â”œâ”€â”€ predict.py          # Module d'infÃ©rence
â”‚   â”œâ”€â”€ spark_io.py         # I/O Spark (MinIO)
â”‚   â”œâ”€â”€ spark_prepare.py    # PrÃ©paration Spark
â”‚   â”œâ”€â”€ spark_session.py    # CrÃ©ation session Spark
â”‚   â”œâ”€â”€ train.py            # Module d'entraÃ®nement (legacy)
â”‚   â”œâ”€â”€ trainer.py          # Trainer modulaire
â”‚   â”œâ”€â”€ utils.py            # Utilitaires
â”‚   â””â”€â”€ validation.py       # Validation des donnÃ©es
â””â”€â”€ tests/
    â”œâ”€â”€ test_ml_plausibility.py  # Tests plausibilitÃ© mÃ©tier
    â”œâ”€â”€ test_ml_quality.py       # Tests qualitÃ© modÃ¨le
    â”œâ”€â”€ test_ml_schema.py        # Tests schÃ©ma ML
    â”œâ”€â”€ test_model_registry.py   # Tests model registry
    â”œâ”€â”€ test_month_range.py      # Tests plage de mois
    â””â”€â”€ test_validation.py       # Tests validation
```

---

## DonnÃ©es utilisÃ©es

### Source

Les donnÃ©es proviennent du dataset officiel **NYC Yellow Taxi Trips**, stockÃ©es sous forme de fichiers Parquet dans MinIO (`nyc-interim`).

### PÃ©rimÃ¨tre temporel

#### Mode Legacy (train.py)
| Phase         | Mois utilisÃ©s       |
|---------------|---------------------|
| EntraÃ®nement  | 2023/01, 2023/02    |
| InfÃ©rence     | 2023/02             |

#### Mode FenÃªtre Glissante (ml_pipeline.py)
| Phase         | Description                              |
|---------------|------------------------------------------|
| EntraÃ®nement  | M-3, M-2, M-1 (3 derniers mois)          |
| Test          | M (mois courant)                         |

### Target

- **`total_amount`** : montant total payÃ© pour une course

---

## Feature Engineering

Les features sont construites dans `src/features.py` et sont **strictement identiques** entre entraÃ®nement et infÃ©rence.

### Variables numÃ©riques

| Feature           | Description                    |
|-------------------|--------------------------------|
| trip_distance     | Distance du trajet (miles)     |
| passenger_count   | Nombre de passagers            |
| trip_duration_min | DurÃ©e du trajet (minutes)      |
| pickup_hour       | Heure de prise en charge       |
| pickup_dayofweek  | Jour de la semaine (0-6)       |
| pickup_month      | Mois (1-12)                    |

### Variables catÃ©gorielles

EncodÃ©es via `StringIndexer` + `OneHotEncoder` :

| Feature           | Description                    |
|-------------------|--------------------------------|
| VendorID          | Fournisseur                    |
| RatecodeID        | Code tarifaire                 |
| payment_type      | Type de paiement               |
| store_and_fwd_flag| Flag store and forward         |
| PULocationID      | Zone de dÃ©part                 |
| DOLocationID      | Zone d'arrivÃ©e                 |

Toutes les features sont assemblÃ©es via `VectorAssembler`.

---

## ModÃ¨le

### Algorithme sÃ©lectionnÃ©

**Gradient Boosted Trees Regressor (GBTRegressor)**

### Justification

- âœ… Performant sur des relations non linÃ©aires
- âœ… Robuste face aux interactions complexes entre variables
- âœ… TrÃ¨s adaptÃ© aux donnÃ©es tabulaires hÃ©tÃ©rogÃ¨nes
- âœ… Disponible nativement dans Spark MLlib
- âœ… InterprÃ©table via feature importance

### HyperparamÃ¨tres

| ParamÃ¨tre  | Valeur |
|------------|--------|
| maxDepth   | 6      |
| maxIter    | 50     |
| seed       | 42     |

---

## EntraÃ®nement

### Split des donnÃ©es

| Ensemble      | Proportion |
|---------------|------------|
| Train         | 80%        |
| Test          | 20%        |

### Pipeline Spark ML

Le pipeline inclut les Ã©tapes suivantes :

1. `StringIndexer` (variables catÃ©gorielles)
2. `OneHotEncoder`
3. `VectorAssembler`
4. `GBTRegressor`

Le modÃ¨le final est sauvegardÃ© dans :
```
models/ex05_spark_model/
```

---

## Ã‰valuation

### MÃ©triques utilisÃ©es

| MÃ©trique | Description                          |
|----------|--------------------------------------|
| RMSE     | Root Mean Square Error               |
| MAE      | Mean Absolute Error                  |
| RÂ²       | Coefficient de dÃ©termination         |

### RÃ©sultats obtenus

```json
{
  "rmse": 5.17,
  "mae": 2.05,
  "r2": 0.94
}
```
---

## Application Streamlit â€“ Visualisation et DÃ©monstration

Une application **Streamlit** a Ã©tÃ© dÃ©veloppÃ©e pour permettre l'exploration interactive des rÃ©sultats du modÃ¨le de prÃ©diction et l'analyse des donnÃ©es. Cette interface facilite la visualisation des prÃ©dictions, des mÃ©triques et des analyses d'erreurs, tout en offrant une expÃ©rience utilisateur simple et efficace.

### FonctionnalitÃ©s principales

- Visualisation des prÃ©dictions du modÃ¨le sur des Ã©chantillons de donnÃ©es
- Affichage des mÃ©triques de performance (RMSE, MAE, RÂ²)
- Analyse d'erreurs par tranche de prix
- Exploration interactive des donnÃ©es d'entrÃ©e et des rÃ©sultats

---
### AperÃ§u de l'application

Ci-dessous quelques captures d'Ã©cran de l'application StreamlitÂ :

<p align="center">
  <img src="../Documents/Captures/ML%20streamlit/1.png" alt="Accueil Streamlit" width="600"/>
  <br/>
  <img src="../Documents/Captures/ML%20streamlit/2.png" alt="MÃ©triques et prÃ©dictions" width="600"/>
  <br/>
  <img src="../Documents/Captures/ML%20streamlit/3.png" alt="Analyse d'erreurs" width="600"/>
  <br/>
  <img src="../Documents/Captures/ML%20streamlit/4.png" alt="Exploration interactive" width="600"/>
</p>

L'application est accessible dans le dossierÂ : `ex05_ml_prediction_service/streamlit_app/app.py`.

Pour lancer l'applicationÂ :

```bash
cd ex05_ml_prediction_service/streamlit_app
streamlit run app.py
```
---

> ğŸ‘‰ La contrainte de l'Ã©noncÃ© (**RMSE < 10**) est largement respectÃ©e.

Les mÃ©triques sont stockÃ©es dans : `reports/train_metrics.json`

---

## Analyse d'erreurs (Error Analysis)

Une analyse d'erreurs complÃ¨te est effectuÃ©e aprÃ¨s l'Ã©valuation du modÃ¨le, permettant de comprendre **oÃ¹ et pourquoi** le modÃ¨le se trompe.

### MÃ©triques calculÃ©es

| MÃ©trique              | Description                                  |
|-----------------------|----------------------------------------------|
| mean_error            | Erreur moyenne (biais du modÃ¨le)             |
| std_error             | Ã‰cart-type des erreurs                       |
| median_error          | Erreur mÃ©diane                               |
| p95_error / p99_error | Percentiles 95 et 99 des erreurs             |
| pct_underestimate     | % de cas oÃ¹ le modÃ¨le sous-estime            |
| pct_overestimate      | % de cas oÃ¹ le modÃ¨le surestime              |

### Analyse par tranche de prix

Les erreurs sont analysÃ©es par bucket de prix :

| Bucket     | Plage ($)   | Description                    |
|------------|-------------|--------------------------------|
| low        | 0 - 10      | Courses courtes / minimum fare |
| medium     | 10 - 30     | Courses standard               |
| high       | 30 - 60     | Courses moyennes-longues       |
| very_high  | > 60        | Airport, longue distance       |

### Identification des causes d'erreurs

Pour les 10 plus fortes erreurs, le systÃ¨me identifie automatiquement les causes probables :

- `long_distance_low_fare_anomaly` : anomalie de donnÃ©es
- `short_trip_high_fare_tips_or_surge` : pourboire ou surge pricing
- `extended_duration_traffic_or_wait` : trafic ou attente
- `night_surge_pricing` : tarification de nuit
- `airport_flat_rate` : tarif forfaitaire aÃ©roport
- `cash_payment_tip_not_recorded` : pourboire cash non enregistrÃ©
- `negotiated_fare` : tarif nÃ©gociÃ©

### Artefacts gÃ©nÃ©rÃ©s

| Fichier                      | Contenu                              |
|------------------------------|--------------------------------------|
| `error_summary.json`         | Statistiques globales + insights     |
| `error_by_price_bucket.json` | Erreurs par tranche de prix          |

---

## InfÃ©rence

L'infÃ©rence est rÃ©alisÃ©e Ã  partir du modÃ¨le sauvegardÃ©, sur un mois distinct.

### Ã‰tapes

1. Chargement du modÃ¨le Spark ML
2. Lecture des donnÃ©es depuis MinIO
3. Application du mÃªme feature engineering
4. Validation des donnÃ©es d'entrÃ©e (Ã©chantillon)
5. GÃ©nÃ©ration des prÃ©dictions

---

## Validation des donnÃ©es

Un module dÃ©diÃ© (`src/validation.py`) vÃ©rifie :

- âœ… PrÃ©sence des colonnes obligatoires
- âœ… Absence de valeurs nÃ©gatives incohÃ©rentes
- âœ… CohÃ©rence temporelle (pickup â‰¤ dropoff)

La validation est appliquÃ©e :
- Avant entraÃ®nement
- Avant infÃ©rence (sur un Ã©chantillon)

---

## QualitÃ© logicielle

### Standards respectÃ©s

| Standard        | Outil          | Statut |
|-----------------|----------------|--------|
| PEP8            | flake8         | âœ…     |
| Auto-formatting | autopep8       | âœ…     |
| Documentation   | NumpyDoc       | âœ…     |
| Tests           | pytest         | âœ…     |

### VÃ©rification PEP8

```bash
flake8 src/
```

---

## Tests Machine Learning

Des tests spÃ©cifiques au ML sont implÃ©mentÃ©s pour garantir la robustesse du pipeline.

### Organisation des tests

| Fichier                    | Phase           | Script associÃ©               |
|----------------------------|-----------------|------------------------------|
| `test_validation.py`       | Pre-training    | `run_tests_pre_train.ps1`    |
| `test_month_range.py`      | Pre-training    | `run_tests_pre_train.ps1`    |
| `test_ml_schema.py`        | Pre-training    | `run_tests_pre_train.ps1`    |
| `test_ml_quality.py`       | Post-training   | `run_tests_post_train.ps1`   |
| `test_ml_plausibility.py`  | Post-prediction | `run_tests_post_predict.ps1` |

### Tests Pre-training (`run_tests_pre_train.ps1`)

VÃ©rifient que les donnÃ©es sont prÃªtes pour l'entraÃ®nement :

- âœ… Colonnes obligatoires prÃ©sentes
- âœ… Valeurs non nÃ©gatives
- âœ… CohÃ©rence temporelle (pickup â‰¤ dropoff)
- âœ… Ranges de mois valides

### Tests Post-training (`run_tests_post_train.ps1`)

VÃ©rifient les seuils de performance du modÃ¨le :

| Test                | Seuil                    | Description                  |
|---------------------|--------------------------|------------------------------|
| RMSE                | < 10.0                   | Exigence du projet           |
| RÂ²                  | > 0.0                    | Meilleur que la moyenne      |
| RÂ² (acceptable)     | > 0.5                    | Bon modÃ¨le                   |
| MAE                 | < 15.0                   | Erreur absolue raisonnable   |
| MAE â‰¤ RMSE          | Toujours                 | CohÃ©rence mathÃ©matique       |

### Tests Post-prediction (`run_tests_post_predict.ps1`)

VÃ©rifient que les prÃ©dictions sont mÃ©tier-valides :

- âœ… PrÃ©dictions non nÃ©gatives (tarifs â‰¥ 0)
- âœ… PrÃ©dictions finies (pas de NaN/Inf)
- âœ… PrÃ©dictions raisonnables (< $500 pour un trajet)
- âœ… Contraintes mÃ©tier NYC Taxi respectÃ©es

---

## ExÃ©cution

### Workflow complet MLOps

Le projet suit un workflow MLOps structurÃ© avec des scripts dÃ©diÃ©s Ã  chaque Ã©tape :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     WORKFLOW MLOps EX05                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. PRE-TRAINING TESTS                                          â”‚
â”‚     .\run_tests_pre_train.ps1                                   â”‚
â”‚     "Est-ce que j'ai le droit d'entraÃ®ner ?"                    â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚  2. TRAINING + ERROR ANALYSIS                                   â”‚
â”‚     .\run_ex05.ps1                                              â”‚
â”‚     "Je produis un modÃ¨le et ses artefacts"                     â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚  3. POST-TRAINING QUALITY TESTS                                 â”‚
â”‚     .\run_tests_post_train.ps1                                  â”‚
â”‚     "Ce modÃ¨le a-t-il le droit d'exister ?"                     â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚  4. PREDICTION / INFERENCE                                      â”‚
â”‚     .\run_predict.ps1                                           â”‚
â”‚     "Je fais de la prÃ©diction"                                  â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚  5. POST-PREDICTION PLAUSIBILITY TESTS                          â”‚
â”‚     .\run_tests_post_predict.ps1                                â”‚
â”‚     "Les rÃ©sultats sont acceptables pour un humain ?"           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Scripts disponibles

| Script                        | RÃ´le                                      | Question clÃ©                              |
|-------------------------------|-------------------------------------------|-------------------------------------------|
| `run_pipeline.ps1`            | **Orchestrateur complet** (legacy + sliding window) | "Pipeline ML complet"             |
| `run_tests_pre_train.ps1`     | Tests schÃ©ma, validation, ranges          | "Puis-je entraÃ®ner ?"                     |
| `run_ex05.ps1`                | EntraÃ®nement Spark (legacy)               | "Produire modÃ¨le + artefacts"             |
| `run_tests_post_train.ps1`    | Tests RMSE < 10, RÂ² > 0, MAE              | "Ce modÃ¨le est-il valide ?"               |
| `run_predict.ps1`             | InfÃ©rence Spark                           | "PrÃ©diction contrÃ´lÃ©e"                    |
| `run_tests_post_predict.ps1`  | Tests plausibilitÃ© mÃ©tier                 | "RÃ©sultats acceptables ?"                 |

### Orchestrateur principal (`run_pipeline.ps1`)

Le script `run_pipeline.ps1` est l'**orchestrateur principal** qui supporte les deux modes :

#### ParamÃ¨tres

| ParamÃ¨tre       | Description                                              |
|-----------------|----------------------------------------------------------|
| `-TestMonth`    | Mois de test (ex: 2023-06). Si omis, utilise le mois courant |
| `-TrainMonths`  | Mois d'entraÃ®nement explicites (ex: 2023-03,2023-04,2023-05) |
| `-SkipMissing`  | Continue avec les donnÃ©es disponibles si certains mois manquent |
| `-Legacy`       | Utilise l'ancien `train.py` avec mois hardcodÃ©s          |
| `-SkipTests`    | Saute les tests de validation (non recommandÃ©)           |
| `-TrainOnly`    | ExÃ©cute uniquement la phase d'entraÃ®nement               |
| `-PredictOnly`  | ExÃ©cute uniquement la phase d'infÃ©rence                  |
| `-Force`        | Force le rÃ©-entraÃ®nement mÃªme si un modÃ¨le existe        |
| `-RegistryPath` | Chemin du registry (dÃ©faut: models/registry)             |
| `-Help`         | Affiche l'aide                                           |

#### Exemples d'utilisation

```powershell
cd ex05_ml_prediction_service

# Pipeline complet avec auto-dÃ©tection du mois
.\run_pipeline.ps1

# Mois de test explicite
.\run_pipeline.ps1 -TestMonth "2023-05"

# Continuer mÃªme si certains mois manquent (min 2 mois de training requis)
.\run_pipeline.ps1 -TestMonth "2023-05" -SkipMissing

# Mode legacy (ancien train.py avec 2023/01-02)
.\run_pipeline.ps1 -Legacy

# EntraÃ®nement seul
.\run_pipeline.ps1 -TestMonth "2023-05" -TrainOnly

# Forcer le rÃ©-entraÃ®nement
.\run_pipeline.ps1 -TestMonth "2023-05" -Force
```

### ExÃ©cution pas Ã  pas (mode legacy)

```powershell
cd ex05_ml_prediction_service

# 1. Valider les donnÃ©es avant entraÃ®nement
.\run_tests_pre_train.ps1

# 2. EntraÃ®ner le modÃ¨le
.\run_ex05.ps1

# 3. VÃ©rifier la qualitÃ© du modÃ¨le
.\run_tests_post_train.ps1

# 4. Lancer l'infÃ©rence
.\run_predict.ps1

# 5. Valider les prÃ©dictions
.\run_tests_post_predict.ps1
```

### Commande spark-submit (manuel)

```bash
spark-submit \
  --master spark://spark-master:7077 \
  --conf spark.driver.extraJavaOptions=-Dlog4j.configurationFile=conf/log4j2.properties \
  src/train.py
```

---

## Variables d'environnement

| Variable             | Description                      | DÃ©faut           |
|----------------------|----------------------------------|------------------|
| MINIO_ENDPOINT       | URL MinIO                        | http://minio:9000|
| MINIO_ACCESS_KEY     | Access key MinIO                 | -                |
| MINIO_SECRET_KEY     | Secret key MinIO                 | -                |
| MINIO_BUCKET_INTERIM | Bucket donnÃ©es nettoyÃ©es         | nyc-interim      |

---

## Performances

| Phase         | DurÃ©e approximative |
|---------------|---------------------|
| EntraÃ®nement  | ~4032 s             |
| InfÃ©rence     | ~84 s               |

---

## Limitations connues

- âŒ Pas de tuning automatique des hyperparamÃ¨tres
- âŒ Pas de gestion de dÃ©rive (data drift)
- âŒ Pas de monitoring temps rÃ©el
- âŒ InfÃ©rence batch uniquement

---

## AmÃ©liorations implÃ©mentÃ©es

- âœ… **Analyse d'erreurs complÃ¨te** : statistiques, buckets, causes mÃ©tier
- âœ… **Tests ML orientÃ©s** : schÃ©ma, plausibilitÃ©, qualitÃ©
- âœ… **Insights automatiques** : justification mÃ©tier des erreurs Ã©levÃ©es
- âœ… **FenÃªtre glissante** : entraÃ®nement sur 3 mois, test sur le mois suivant
- âœ… **Model Registry** : gestion current/candidate avec promotion automatique
- âœ… **RÃ¨gle de promotion** : 2/3 mÃ©triques doivent s'amÃ©liorer (RMSE, MAE, RÂ²)
- âœ… **Validation des donnÃ©es** : vÃ©rification de disponibilitÃ© avant entraÃ®nement
- âœ… **Mode tolÃ©rant** : continue avec donnÃ©es disponibles (min 2 mois training)
- âœ… **Auto-dÃ©tection du mois** : utilise le mois courant si non spÃ©cifiÃ©
- âœ… **Idempotence** : script exÃ©cutable plusieurs fois sans effet de bord

---

## Perspectives futures

Plusieurs extensions MLOps sont envisageables :

- ğŸ”„ IntÃ©gration Airflow pour orchestration mensuelle automatisÃ©e (EX06)
- ğŸ“¦ Versionnement avancÃ© du modÃ¨le (MLflow)
- ğŸš€ DÃ©ploiement via API ou front-end
- ğŸ“ˆ Monitoring et dÃ©tection de dÃ©rive
- ğŸ”§ Hyperparameter tuning automatique

---

## ğŸ“‹ Logging StructurÃ©

### Configuration CentralisÃ©e

Le module `logging_config.py` fournit un systÃ¨me de logging standardisÃ© pour tout le pipeline ML.

### Format des Logs

```
2024-06-15 14:30:25 | INFO     | src.ml_pipeline            | Pipeline started
2024-06-15 14:30:26 | INFO     | src.trainer                | Training on 2,500,000 rows
2024-06-15 14:35:42 | WARNING  | src.ml_pipeline            | Missing data for ['2023/03']
```

### Utilisation

```python
from logging_config import get_logger, PipelineLogger

# Logger simple
logger = get_logger(__name__)
logger.info("Message")
logger.warning("Attention")
logger.error("Erreur")

# Logger avec tracking de mÃ©triques
pipeline_log = PipelineLogger("MLPipeline")
pipeline_log.stage_start("training", months=["2023/01", "2023/02"])
# ... training ...
pipeline_log.stage_end("training", row_count=2500000)
pipeline_log.verify_retention("load_raw", "after_cleaning", min_threshold=0.80)
pipeline_log.summary()
```

### Classes Disponibles

| Classe | Description |
|--------|-------------|
| `get_logger(name)` | Logger standard avec format uniforme |
| `PipelineLogger` | Logger avec tracking de mÃ©triques et vÃ©rification de rÃ©tention |
| `configure_file_logging()` | Ajoute l'Ã©criture vers fichier |

### Avantages

- âœ… **Timestamps** : TraÃ§abilitÃ© temporelle complÃ¨te
- âœ… **Niveaux** : INFO, WARNING, ERROR pour filtrage
- âœ… **Modules** : Identification de la source du log
- âœ… **RÃ©tention** : VÃ©rification automatique perte de donnÃ©es
- âœ… **Production-ready** : Compatible avec ELK, CloudWatch, etc.

---

## IntÃ©gration Airflow (EX06)

Le script `ml_pipeline.py` est conÃ§u pour Ãªtre appelÃ© par Airflow :

```python
from airflow.operators.bash import BashOperator

train_task = BashOperator(
    task_id='train_model',
    bash_command='cd /opt/workdir/ex05_ml_prediction_service && python src/ml_pipeline.py --test-month {{ ds[:7] }}'
)
```

Le script est **idempotent** : toute la logique mÃ©tier (comparaison, promotion) reste dans EX05.

---

## Conclusion

Cet exercice constitue une premiÃ¨re implÃ©mentation complÃ¨te d'un **pipeline ML distribuÃ©**, intÃ©grÃ©e dans une architecture Big Data existante. Il pose les bases solides d'une dÃ©marche MLOps, tout en respectant les contraintes industrielles : **reproductibilitÃ©**, **qualitÃ© du code**, **traÃ§abilitÃ©** et **performance**.

---

---

## Statut

âœ… **TerminÃ© et validÃ©**

---

**Auteur :** MAAOUIA Ahmed â€“ CY Tech Big Data
