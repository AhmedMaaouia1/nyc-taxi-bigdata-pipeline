# RAPPORT DE PROJET BIG DATA
## Pipeline de Traitement des DonnÃ©es NYC Taxi

---

**Auteur** : Ahmed Maaouia  
**Formation** : CY Tech - Master Big Data (2024-2025)  
**Date de rendu** : Janvier 2026  
**Lien GitHub** : https://github.com/AhmedMaaouia1/nyc-taxi-bigdata-pipeline

---

## TABLE DES MATIÃˆRES

1. [Introduction](#1-introduction)
2. [Architecture Globale](#2-architecture-globale)
3. [Exercice 1 - Data Retrieval](#3-exercice-1---data-retrieval)
4. [Exercice 2 - Data Ingestion](#4-exercice-2---data-ingestion)
5. [Exercice 3 - Data Warehouse](#5-exercice-3---data-warehouse)
6. [Exercice 4 - Dashboard & EDA](#6-exercice-4---dashboard--eda)
7. [Exercice 5 - ML Prediction Service](#7-exercice-5---ml-prediction-service)
8. [Exercice 6 - Orchestration Airflow](#8-exercice-6---orchestration-airflow)
9. [DifficultÃ©s RencontrÃ©es et Solutions](#9-difficultÃ©s-rencontrÃ©es-et-solutions)
10. [Conclusion et Perspectives](#10-conclusion-et-perspectives)
11. [Annexes](#11-annexes)

---

## 1. INTRODUCTION

### 1.1 Contexte

Ce projet s'inscrit dans le cadre du cours de Big Data (annÃ©e universitaire 2024-2025) et vise Ã  mettre en pratique les concepts de traitement de donnÃ©es massives Ã  travers un cas concret : l'analyse des courses de taxi Ã  New York City.

Le dataset utilisÃ© provient du NYC Taxi & Limousine Commission (TLC) et contient les donnÃ©es des courses de taxis jaunes (Yellow Cab) de Manhattan et des autres boroughs de New York. Chaque mois reprÃ©sente environ **3 millions de courses**, soit plus de **36 millions de lignes par an**.

### 1.2 Objectifs du Projet

Le projet vise Ã  construire un pipeline Big Data complet, de bout en bout, capable de :

1. **Collecter** les donnÃ©es mensuellement depuis la source officielle NYC TLC
2. **Nettoyer et transformer** les donnÃ©es avec Apache Spark
3. **Stocker** les donnÃ©es dans un Data Warehouse relationnel
4. **Visualiser** les donnÃ©es via un Dashboard interactif
5. **PrÃ©dire** le prix des courses avec un modÃ¨le de Machine Learning
6. **Orchestrer** l'ensemble du pipeline avec Apache Airflow

### 1.3 Stack Technique

| Composant | Technologie | Version | Justification |
|-----------|-------------|---------|---------------|
| Traitement distribuÃ© | Apache Spark | 3.5.x | Standard industrie pour le Big Data |
| Langage EX01/EX02 | Scala | 2.12 | Performance et typage fort |
| Langage EX05 | Python/PySpark | 3.10 | Ã‰cosystÃ¨me ML riche |
| Data Lake | MinIO | Latest | Compatible S3, gratuit, dÃ©ployable localement |
| Data Warehouse | PostgreSQL | 15 | SQL standard, robuste, Open Source |
| Machine Learning | PySpark MLlib | 3.5.x | IntÃ©grÃ© Ã  Spark, scalable |
| Dashboard | Streamlit | Latest | DÃ©veloppement rapide, interactif |
| Orchestration | Apache Airflow | 2.8.1 | Standard industrie, backfill natif |
| Conteneurisation | Docker Compose | Latest | ReproductibilitÃ©, isolation |

---

## 2. ARCHITECTURE GLOBALE

### 2.1 Vue d'Ensemble

L'architecture du projet suit le pattern **Lakehouse**, combinant les avantages d'un Data Lake (stockage flexible, scalable) et d'un Data Warehouse (requÃªtes SQL, schÃ©ma structurÃ©).

<!-- CAPTURE_ARCHITECTURE : InsÃ©rer ici Documents/Project_Architecture.png -->
**[CAPTURE Ã€ INSÃ‰RER : Documents/Project_Architecture.png - Vue globale de l'architecture]**

### 2.2 Infrastructure Docker

L'ensemble de l'infrastructure est dÃ©ployÃ©e via Docker Compose, garantissant la reproductibilitÃ© et l'isolation des composants.

| Conteneur | RÃ´le | Port |
|-----------|------|------|
| spark-master | Coordinateur Spark | 8081, 7077 |
| spark-worker-1 | ExÃ©cuteur Spark | 8082 |
| spark-worker-2 | ExÃ©cuteur Spark | 8083 |
| minio | Data Lake S3 | 9000, 9001 |
| postgres | Data Warehouse | 5432 |
| airflow-webserver | UI Airflow | 8080 |
| airflow-scheduler | Orchestrateur | - |
| streamlit | Dashboard | 8501 |

Tous les conteneurs partagent le rÃ©seau Docker `nyc-net`, permettant la communication inter-services.

### 2.3 Architecture Data Lake (MinIO)

Le Data Lake MinIO est organisÃ© en **3 zones** suivant le pattern Medallion :

| Bucket | Zone | Statut | Description |
|--------|------|--------|-------------|
| `nyc-raw` | Bronze (Raw Zone) | âœ… UtilisÃ© | DonnÃ©es brutes tÃ©lÃ©chargÃ©es depuis NYC TLC |
| `nyc-interim` | Silver (Interim Zone) | âœ… UtilisÃ© | DonnÃ©es nettoyÃ©es et transformÃ©es par EX02 |
| `nyc-processed` | Gold (Curated Zone) | ğŸ”® **PrÃ©vu** | Zone rÃ©servÃ©e pour Ã©volutions futures |

#### Zone `nyc-processed` : Ã‰volutions Futures PrÃ©vues

La zone **Gold (`nyc-processed`)** est provisionnÃ©e mais non utilisÃ©e dans la version actuelle. Elle est destinÃ©e Ã  accueillir :

| Ã‰volution | Description | Cas d'usage |
|-----------|-------------|-------------|
| **PrÃ©dictions ML** | Stockage des prÃ©dictions de prix gÃ©nÃ©rÃ©es par le modÃ¨le | Batch scoring mensuel, export vers BI |
| **AgrÃ©gations** | DonnÃ©es prÃ©-agrÃ©gÃ©es par zone, heure, jour | Dashboard temps rÃ©el, KPIs mÃ©tier |
| **Features Store** | Features prÃ©-calculÃ©es pour le ML | RÃ©utilisation cross-modÃ¨les, cohÃ©rence |
| **Data Products** | Datasets prÃªts Ã  consommer pour les utilisateurs finaux | Self-service analytics, API data |

Cette architecture en 3 zones permet une **Ã©volution progressive** sans refonte majeure.

### 2.4 Flux de DonnÃ©es

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FLUX DE DONNÃ‰ES                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚   NYC TLC Website                                                        â”‚
â”‚        â”‚                                                                 â”‚
â”‚        â–¼                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚   â”‚  EX01   â”‚â”€â”€â”€â”€â–ºâ”‚  MinIO: nyc-raw/yellow/YYYY/MM/     â”‚  BRONZE       â”‚
â”‚   â”‚ Retrievalâ”‚     â”‚  (DonnÃ©es brutes Parquet)          â”‚               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚        â”‚                                                                 â”‚
â”‚        â–¼                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚   â”‚  EX02   â”‚â”€â”€â”€â”€â–ºâ”‚  MinIO: nyc-interim/yellow/YYYY/MM/ â”‚  SILVER       â”‚
â”‚   â”‚Ingestionâ”‚     â”‚  (DonnÃ©es nettoyÃ©es Parquet)        â”‚               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚        â”‚                                                                 â”‚
â”‚        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚        â”‚          â”‚  PostgreSQL: yellow_trips_staging   â”‚               â”‚
â”‚        â”‚          â”‚  (Table staging temporaire)         â”‚               â”‚
â”‚        â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚        â”‚                         â”‚                                       â”‚
â”‚        â”‚                         â–¼                                       â”‚
â”‚        â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚        â”‚          â”‚  EX03: Data Warehouse               â”‚               â”‚
â”‚        â”‚          â”‚  - fact_trip                        â”‚               â”‚
â”‚        â”‚          â”‚  - dim_date, dim_time               â”‚               â”‚
â”‚        â”‚          â”‚  - dim_location, dim_vendor         â”‚               â”‚
â”‚        â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚        â”‚                                                                 â”‚
â”‚        â–¼                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚   â”‚  EX05   â”‚â”€â”€â”€â”€â–ºâ”‚  Model Registry (fichiers locaux)   â”‚               â”‚
â”‚   â”‚   ML    â”‚     â”‚  - candidate_model/                 â”‚               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  - current_model/                   â”‚               â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚        â”‚                                                                 â”‚
â”‚        â–¼ (FUTUR)                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚   â”‚  MinIO: nyc-processed/                              â”‚  GOLD         â”‚
â”‚   â”‚  (PrÃ©dictions, agrÃ©gations, features store)         â”‚  (PRÃ‰VU)      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.5 Choix d'Architecture

| DÃ©cision | Alternative considÃ©rÃ©e | Justification du choix |
|----------|------------------------|------------------------|
| MinIO vs HDFS | HDFS | MinIO est plus lÃ©ger, compatible S3, facile Ã  dÃ©ployer |
| PostgreSQL vs Hive | Hive | PostgreSQL est plus rapide pour les requÃªtes analytiques simples |
| Airflow vs Prefect | Prefect | Airflow est le standard industrie, meilleur pour le CV |
| LocalExecutor vs Celery | CeleryExecutor | Suffisant pour le volume du projet, plus simple |
| 3 zones Data Lake | 2 zones | PrÃ©pare l'Ã©volution future (Gold zone prÃªte) |

---

## 3. EXERCICE 1 - DATA RETRIEVAL

### 3.1 Objectif

TÃ©lÃ©charger automatiquement les fichiers Parquet mensuels depuis le site NYC TLC et les stocker dans le Data Lake MinIO (zone Raw/Bronze).

### 3.2 ImplÃ©mentation

**Langage** : Scala 2.12  
**Fichier principal** : `ex01_data_retrieval/src/main/scala/Ex01DataRetrieval.scala`

Le job Spark accepte deux paramÃ¨tres :
- `--year` : AnnÃ©e (ex: 2023)
- `--month` : Mois (ex: 01)

**Flux d'exÃ©cution** :
1. VÃ©rification si le fichier existe dÃ©jÃ  localement (idempotence)
2. TÃ©lÃ©chargement depuis `https://d37ci6vzurychx.cloudfront.net/trip-data/`
3. Lecture du fichier Parquet avec Spark
4. Ã‰criture vers MinIO (`s3a://nyc-raw/yellow/YYYY/MM/`)

### 3.3 Idempotence

L'idempotence est garantie par deux mÃ©canismes :
1. **Skip du tÃ©lÃ©chargement** si le fichier existe dÃ©jÃ  localement
2. **Mode overwrite** sur MinIO pour Ã©craser les donnÃ©es existantes

```scala
df.write
  .mode("overwrite")
  .parquet(s3TargetPath)  // s3a://nyc-raw/yellow/2023/01/
```

> âš ï¸ **PrÃ©cision importante** : L'overwrite est **limitÃ© Ã  la partition mensuelle `YYYY/MM/`** (ex: `nyc-raw/yellow/2023/01/`), et non Ã  tout le bucket. Ainsi, rÃ©Ã©crire janvier 2023 n'affecte pas les autres mois. Chaque mois est une partition indÃ©pendante.

### 3.4 Commande d'ExÃ©cution

```bash
docker exec spark-master spark-submit \
    --class Ex01DataRetrieval \
    --master spark://spark-master:7077 \
    /opt/workdir/ex01_data_retrieval/target/scala-2.12/ex01-data-retrieval_2.12-0.1.0.jar \
    --year 2023 --month 01
```

### 3.5 Capture d'Ã‰cran

<!-- CAPTURE_EX01_MINIO : Console MinIO montrant nyc-raw/yellow/2023/01/ avec les fichiers parquet -->
**[CAPTURE Ã€ INSÃ‰RER : Console MinIO â†’ Bucket nyc-raw â†’ yellow/2023/01/ avec les fichiers parquet listÃ©s]**

---

## 4. EXERCICE 2 - DATA INGESTION

### 4.1 Objectif

Nettoyer les donnÃ©es brutes et les Ã©crire vers deux destinations :
- **Branch 1** : MinIO (zone Interim/Silver) - Pour le ML
- **Branch 2** : PostgreSQL (table staging) - Pour le Data Warehouse

### 4.2 Architecture Double Branche

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚          EX02 Spark Job            â”‚
                    â”‚                                    â”‚
   nyc-raw â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  1. Lecture Parquet                â”‚
   (Bronze)         â”‚  2. Nettoyage & Filtrage           â”‚
                    â”‚  3. SÃ©lection colonnes             â”‚
                    â”‚                                    â”‚
                    â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
                    â”‚         â”‚   Branch 1  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ MinIO nyc-interim (Silver)
                    â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
                    â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
                    â”‚         â”‚   Branch 2  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ PostgreSQL (staging)
                    â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.3 Transformations AppliquÃ©es

| Transformation | Description |
|----------------|-------------|
| Filtrage nulls | Suppression des lignes avec colonnes critiques nulles |
| Filtrage valeurs | `fare_amount > 0`, `trip_distance > 0`, `passenger_count > 0` |
| SÃ©lection colonnes | 18 colonnes retenues sur 19 originales |
| Cast types | Conversion des types pour compatibilitÃ© PostgreSQL |

### 4.4 Idempotence

| Branche | MÃ©canisme | Scope |
|---------|-----------|-------|
| MinIO | `mode("overwrite")` | Partition mensuelle `YYYY/MM/` uniquement |
| PostgreSQL | `mode("overwrite")` + `option("truncate", "true")` | Table entiÃ¨re |

> ğŸ’¡ **Justification du TRUNCATE sur staging** : La table `yellow_trips_staging` est **volontairement technique et rejouable**. Elle ne sert qu'au chargement analytique vers le Data Warehouse (EX03) et n'a pas vocation Ã  historiser les donnÃ©es. Reconstruire le staging Ã  chaque run mensuel garantit la cohÃ©rence et simplifie le debug.

### 4.5 Captures d'Ã‰cran

<!-- CAPTURE_EX02_MINIO : Console MinIO montrant nyc-interim/yellow/2023/01/ -->
**[CAPTURE Ã€ INSÃ‰RER : Console MinIO â†’ Bucket nyc-interim â†’ yellow/2023/01/]**

<!-- CAPTURE_EX02_STAGING : pgAdmin/DBeaver montrant SELECT COUNT(*) FROM yellow_trips_staging -->
**[CAPTURE Ã€ INSÃ‰RER : pgAdmin ou DBeaver â†’ RequÃªte SELECT COUNT(*) FROM yellow_trips_staging avec rÃ©sultat]**

---

## 5. EXERCICE 3 - DATA WAREHOUSE

### 5.1 Objectif

Construire un Data Warehouse en modÃ¨le Ã©toile (Star Schema) et charger les donnÃ©es depuis la table staging.

### 5.2 ModÃ¨le Dimensionnel

```
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   dim_vendor    â”‚
                              â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
                              â”‚ vendor_id (PK)  â”‚
                              â”‚ vendor_name     â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    dim_date     â”‚           â”‚                 â”‚           â”‚  dim_location   â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚           â”‚                 â”‚           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ date_id (PK)    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   fact_trip     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ location_id (PK)â”‚
â”‚ year            â”‚           â”‚                 â”‚           â”‚ borough         â”‚
â”‚ month           â”‚           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚           â”‚ zone            â”‚
â”‚ day             â”‚           â”‚ trip_id (PK)    â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ day_of_week     â”‚           â”‚ pickup_date (FK)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚ pickup_time (FK)â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚ vendor_id (FK)  â”‚           â”‚ dim_payment_typeâ”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚ payment_type_id â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚    dim_time     â”‚           â”‚ ratecode_id (FK)â”‚           â”‚ payment_type_id â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚           â”‚ pickup_loc (FK) â”‚           â”‚ payment_name    â”‚
â”‚ time_id (PK)    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ dropoff_loc (FK)â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ hour            â”‚           â”‚ passenger_count â”‚
â”‚ minute          â”‚           â”‚ trip_distance   â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚ fare_amount     â”‚           â”‚  dim_ratecode   â”‚
                              â”‚ total_amount    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
                              â”‚ ...             â”‚           â”‚ ratecode_id (PK)â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚ ratecode_name   â”‚
                                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.3 Tables CrÃ©Ã©es

| Table | Type | Lignes (exemple) | Description |
|-------|------|------------------|-------------|
| fact_trip | Fait | ~3,000,000/mois | Courses de taxi |
| dim_date | Dimension | ~365 | Dates uniques |
| dim_time | Dimension | ~1,440 | Minutes de la journÃ©e |
| dim_location | Dimension | ~265 | Zones NYC |
| dim_vendor | Dimension | 2 | Compagnies de taxi |
| dim_payment_type | Dimension | 5 | Modes de paiement |
| dim_ratecode | Dimension | 6 | Types de tarification |

### 5.4 Idempotence avec ON CONFLICT

```sql
INSERT INTO fact_trip (...)
SELECT ... FROM yellow_trips_staging
ON CONFLICT DO NOTHING;
```

> ğŸ”‘ **ClÃ© de dÃ©tection des doublons** : Les doublons sont Ã©vitÃ©s via une **contrainte d'unicitÃ© composite** sur les colonnes `(pickup_date, pickup_time, pickup_location_id, dropoff_location_id, vendor_id)`. Cette combinaison identifie de maniÃ¨re unique une course. Le `ON CONFLICT DO NOTHING` ignore silencieusement les insertions de lignes dÃ©jÃ  prÃ©sentes, garantissant l'idempotence.

Le `ON CONFLICT DO NOTHING` garantit que :
- Les doublons ne sont pas insÃ©rÃ©s
- Le job peut Ãªtre rejouÃ© sans erreur
- Les donnÃ©es existantes sont prÃ©servÃ©es

### 5.5 Captures d'Ã‰cran

<!-- CAPTURE_EX03_FACT_COUNT : pgAdmin montrant SELECT COUNT(*) FROM fact_trip avec rÃ©sultat -->
**[CAPTURE Ã€ INSÃ‰RER : pgAdmin â†’ RequÃªte SELECT COUNT(*) FROM fact_trip avec le nombre de lignes]**

<!-- CAPTURE_EX03_SCHEMA : pgAdmin montrant la liste des tables (fact_trip + dim_*) -->
**[CAPTURE Ã€ INSÃ‰RER : pgAdmin â†’ Vue des tables du schÃ©ma avec fact_trip et toutes les dim_*]**

---

## 6. EXERCICE 4 - DASHBOARD & EDA

### 6.1 Objectif

Explorer les donnÃ©es via un notebook Jupyter et crÃ©er un Dashboard interactif avec Streamlit.

### 6.2 Analyses Exploratoires (EDA)

Le notebook `ex04_eda.ipynb` contient les analyses suivantes :

| Analyse | Insight principal |
|---------|-------------------|
| Distribution des prix | MÃ©diane ~$15, queue longue vers les hauts montants |
| CorrÃ©lation distance/prix | CorrÃ©lation forte (~0.85) |
| Analyse temporelle | Pics Ã  8h et 18h (heures de pointe) |
| Zones frÃ©quentÃ©es | Manhattan domine largement |
| SaisonnalitÃ© | Plus de courses en dÃ©cembre |

### 6.3 Dashboard Streamlit

**URL d'accÃ¨s** : http://localhost:8501

**FonctionnalitÃ©s du Dashboard** :
- Vue d'ensemble avec KPIs principaux
- Graphiques interactifs
- Filtres par date, zone, type de paiement
- Carte des zones NYC
- Analyse des tendances temporelles

> ğŸ“Š **Architecture du Dashboard** : ConformÃ©ment aux contraintes du projet, **Plotly est utilisÃ© uniquement pour l'affichage visuel**. Toutes les agrÃ©gations et calculs sont effectuÃ©s **cÃ´tÃ© PostgreSQL via des requÃªtes SQL**. Le code Python ne fait que rÃ©cupÃ©rer les rÃ©sultats prÃ©-agrÃ©gÃ©s et les afficher, sans transformation mÃ©tier.

### 6.4 Captures d'Ã‰cran Dashboard

<!-- CAPTURE_EX04_DASHBOARD_HOME : Page d'accueil du Dashboard avec KPIs principaux -->
**[CAPTURE Ã€ INSÃ‰RER : Dashboard Streamlit â†’ Page d'accueil avec les KPIs (nombre courses, revenu total, distance moyenne)]**

<!-- CAPTURE_EX04_DASHBOARD_DISTRIBUTION : Graphique de distribution des prix -->
**[CAPTURE Ã€ INSÃ‰RER : Dashboard Streamlit â†’ Histogramme de distribution des prix (total_amount)]**

<!-- CAPTURE_EX04_DASHBOARD_MAP : Carte des zones ou heatmap -->
**[CAPTURE Ã€ INSÃ‰RER : Dashboard Streamlit â†’ Carte ou heatmap des zones les plus frÃ©quentÃ©es]**

<!-- CAPTURE_EX04_DASHBOARD_TEMPORAL : Analyse temporelle (heures de pointe) -->
**[CAPTURE Ã€ INSÃ‰RER : Dashboard Streamlit â†’ Graphique des courses par heure de la journÃ©e]**

<!-- CAPTURE_EX04_DASHBOARD_FILTERS : Interface avec filtres actifs -->
**[CAPTURE Ã€ INSÃ‰RER : Dashboard Streamlit â†’ Vue avec filtres (date, zone, payment_type) appliquÃ©s]**

---

## 7. EXERCICE 5 - ML PREDICTION SERVICE

### 7.1 Objectif

DÃ©velopper un service de prÃ©diction du prix total d'une course (`total_amount`) en utilisant PySpark MLlib.

### 7.2 StratÃ©gie de FenÃªtre Glissante

Pour Ã©viter le **data leakage** et simuler un environnement de production, nous utilisons une stratÃ©gie de **fenÃªtre glissante** (sliding window) :

```
Mois M (test)     : 2023-04
Mois training     : 2023-01, 2023-02, 2023-03  (3 mois prÃ©cÃ©dents)

Mois M+1 (test)   : 2023-05
Mois training     : 2023-02, 2023-03, 2023-04  (fenÃªtre dÃ©calÃ©e)
```

### 7.3 Features UtilisÃ©es

| Feature | Type | Description | Transformation |
|---------|------|-------------|----------------|
| trip_distance | NumÃ©rique | Distance en miles | StandardScaler |
| passenger_count | NumÃ©rique | Nombre de passagers | - |
| hour_of_day | NumÃ©rique | Heure de prise en charge | Extrait de pickup_datetime |
| day_of_week | NumÃ©rique | Jour de la semaine (0-6) | Extrait de pickup_datetime |
| PULocationID | CatÃ©goriel | Zone de dÃ©part | StringIndexer |
| DOLocationID | CatÃ©goriel | Zone d'arrivÃ©e | StringIndexer |

### 7.4 Algorithme : Gradient Boosted Trees

Nous utilisons **GBTRegressor** de PySpark MLlib :

```python
gbt = GBTRegressor(
    featuresCol="features",
    labelCol="total_amount",
    maxIter=50,
    maxDepth=5,
    stepSize=0.1
)
```

**Justification** : GBT offre un bon compromis entre performance et interprÃ©tabilitÃ©, et gÃ¨re bien les features numÃ©riques et catÃ©gorielles.

### 7.5 Model Registry

Le systÃ¨me de Model Registry gÃ¨re automatiquement :

```
models/registry/
â”œâ”€â”€ current_model/          # ModÃ¨le en production
â”‚   â”œâ”€â”€ model/              # Fichiers du modÃ¨le Spark
â”‚   â””â”€â”€ metadata.json       # MÃ©triques et infos
â”œâ”€â”€ candidate_model/        # Nouveau modÃ¨le Ã  Ã©valuer
â”‚   â”œâ”€â”€ model/
â”‚   â””â”€â”€ metadata.json
â””â”€â”€ promotion_history.json  # Historique des promotions
```

**RÃ¨gle de promotion** : Le candidat est promu si **au moins 2 mÃ©triques sur 3** s'amÃ©liorent :
- RMSE (doit diminuer)
- RÂ² (doit augmenter)
- MAE (doit diminuer)

### 7.6 RÃ©sultats Obtenus

| MÃ©trique | Valeur | Seuil projet | Statut |
|----------|--------|--------------|--------|
| **RMSE** | **5.17** | < 10 | âœ… Atteint |
| **RÂ²** | **0.9423** | > 0.5 | âœ… Atteint |
| **MAE** | **2.05** | - | âœ… Excellent |

Ces rÃ©sultats dÃ©montrent que le modÃ¨le prÃ©dit le prix d'une course avec une erreur moyenne de **$2.05** et explique **94.23%** de la variance des prix.

<!-- CAPTURE_EX05_METRICS : Fichier train_metrics.json ou sortie console montrant RMSE/MAE/RÂ² -->
**[CAPTURE Ã€ INSÃ‰RER : Contenu du fichier reports/train_metrics.json OU sortie console du training avec les mÃ©triques]**

<!-- CAPTURE_EX05_STREAMLIT_ML : Interface Streamlit ML Demo si disponible -->
**[CAPTURE Ã€ INSÃ‰RER : Dashboard Streamlit ML Demo montrant les prÃ©dictions (optionnel)]**

### 7.7 Logging StructurÃ©

Le module EX05 utilise un systÃ¨me de logging standardisÃ© via le module `logging_config.py` :

```python
from logging_config import get_logger

logger = get_logger(__name__)
logger.info("Training started for month 2023-04")
```

Format des logs :
```
2026-01-09 14:30:00 | INFO     | ml_pipeline              | Training started for month 2023-04
```

---

## 8. EXERCICE 6 - ORCHESTRATION AIRFLOW

### 8.1 Objectif

Orchestrer le pipeline complet (EX01 â†’ EX05) de maniÃ¨re mensuelle, idempotente et rattrapable (backfill).

### 8.2 Architecture Airflow

| Composant | Configuration |
|-----------|---------------|
| Executor | LocalExecutor |
| Base de donnÃ©es | PostgreSQL (airflow-postgres) |
| Schedule | `@monthly` |
| Start date | 2023-01-01 |
| End date | 2023-05-31 (5 mois) |
| Catchup | ActivÃ© (backfill possible) |

> ğŸ“… **Note sur la pÃ©riode** : Le DAG est configurÃ© avec `end_date=2023-05-31`, ce qui limite le traitement aux mois de **Janvier Ã  Mai 2023** (5 mois). Cette limitation est volontaire pour les besoins du projet. Pour traiter d'autres mois, il suffit de modifier la valeur `end_date` dans le fichier `full_pipeline_dag.py`.

### 8.3 DAG Principal : `full_nyc_taxi_pipeline`

```
start_pipeline
      â”‚
      â–¼
log_pipeline_params
      â”‚
      â–¼
check_source_data_available â”€â”€â”€â”€â”€â–º (short-circuit si donnÃ©es indisponibles)
      â”‚
      â–¼
ex01_start â†’ ex01_spark_submit â†’ ex01_verify â†’ ex01_complete
                                                      â”‚
                                                      â–¼
ex02_start â†’ ex02_spark_submit â”€â”¬â”€â–º ex02_verify_minio_interim â”€â”€â”€â”€â”
                                â”‚                                  â”‚
                                â””â”€â–º ex02_verify_postgres_staging â”€â”€â”¼â”€â–º ex02_quality_check
                                                                   â”‚           â”‚
                                                                   â–¼           â–¼
                                                              ex02_complete
                                                                   â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚                                                              â”‚
                                    â–¼                                                              â–¼
ex03_start â†’ ex03_load_dimensions â†’ ex03_load_fact_trip â†’ ex03_verify â†’ ex03_complete    ex05_check_can_run
                                                                              â”‚                    â”‚
                                                                              â”‚                    â–¼
                                                                              â”‚           ex05_compute_ml_params
                                                                              â”‚                    â”‚
                                                                              â”‚                    â–¼
                                                                              â”‚           ex05_start â†’ ex05_run_ml â†’ ex05_verify â†’ ex05_complete
                                                                              â”‚                                                          â”‚
                                                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                                                           â”‚
                                                                                                           â–¼
                                                                                                    pipeline_success
                                                                                                           â”‚
                                                                                                           â–¼
                                                                                                  log_pipeline_completion
```

### 8.4 FonctionnalitÃ©s AvancÃ©es

#### SLA (Service Level Agreement)

| TÃ¢che | SLA | Justification |
|-------|-----|---------------|
| ex01_spark_submit | 30 min | TÃ©lÃ©chargement + upload |
| ex02_spark_submit | 1h30 | Nettoyage de ~3M lignes |
| ex03_load_fact_trip | 1h | Insertion SQL |
| ex05_run_ml_pipeline | 2h30 | Training ML |

#### Quality Checks

VÃ©rification du comptage inter-Ã©tapes avec seuils :
- **< 80%** : FAIL (perte de donnÃ©es critique)
- **80-90%** : WARNING (log mais continue)
- **> 90%** : OK

#### Idempotence par Exercice

| Exercice | MÃ©canisme | Scope |
|----------|-----------|-------|
| EX01 | Skip si fichier existe + overwrite MinIO | Partition `YYYY/MM/` |
| EX02 | Overwrite MinIO + TRUNCATE staging | Partition + table entiÃ¨re |
| EX03 | ON CONFLICT DO NOTHING | ClÃ© composite |
| EX05 | ModÃ¨le candidat + promotion conditionnelle | ModÃ¨le |

### 8.5 Captures d'Ã‰cran Airflow

<!-- CAPTURE_EX06_DAG_LIST : Vue liste des DAGs dans Airflow avec full_nyc_taxi_pipeline visible -->
**[CAPTURE Ã€ INSÃ‰RER : Airflow UI â†’ Page DAGs montrant full_nyc_taxi_pipeline dans la liste]**

<!-- CAPTURE_EX06_DAG_GRAPH : Graph view du DAG full_nyc_taxi_pipeline montrant toutes les tÃ¢ches -->
**[CAPTURE Ã€ INSÃ‰RER : Airflow UI â†’ Graph view du DAG avec toutes les tÃ¢ches et dÃ©pendances visibles]**

<!-- CAPTURE_EX06_DAG_TREE : Tree view montrant l'historique d'exÃ©cution (runs successifs) -->
**[CAPTURE Ã€ INSÃ‰RER : Airflow UI â†’ Tree view ou Grid view montrant plusieurs exÃ©cutions (success/failed)]**

<!-- CAPTURE_EX06_TASK_LOG : Logs d'une tÃ¢che (ex: ex01_spark_submit ou ex05_run_ml) -->
**[CAPTURE Ã€ INSÃ‰RER : Airflow UI â†’ Logs d'une tÃ¢che montrant les messages de succÃ¨s]**

---

## 9. DIFFICULTÃ‰S RENCONTRÃ‰ES ET SOLUTIONS

### 9.1 ProblÃ¨mes Techniques

| ProblÃ¨me | SymptÃ´me | Solution |
|----------|----------|----------|
| Connexion Spark â†” MinIO | `NoSuchBucket` ou `AccessDenied` | Configuration S3A avec `fs.s3a.endpoint` + credentials AWS |
| Timeout tÃ©lÃ©chargement | Job EX01 timeout aprÃ¨s 30min | Retry avec dÃ©lai exponentiel (3 retries, 2min delay) |
| MÃ©moire Spark insuffisante | `OutOfMemoryError` sur Worker | Ajustement `driver-memory=4g`, `executor-memory=4g` |
| Permissions Docker Windows | Erreurs de permissions Airflow | `AIRFLOW_UID=50000` dans le fichier `.env` |
| RÃ©seau Docker | Conteneurs ne se voient pas | CrÃ©ation du rÃ©seau partagÃ© `nyc-net` |

### 9.2 Choix de Conception

| DÃ©cision | Alternatives | Justification |
|----------|--------------|---------------|
| Scala pour EX01/EX02 | Python | Performance, typage fort, moins d'erreurs runtime |
| Python pour EX05 | Scala | Ã‰cosystÃ¨me ML riche, facilitÃ© de dÃ©veloppement |
| LocalExecutor | CeleryExecutor | Suffisant pour 1 DAG, pas besoin de Redis/RabbitMQ |
| ON CONFLICT DO NOTHING | UPSERT | Plus simple, les corrections de donnÃ©es sources sont rares |
| 1 DAG unique | Multi-DAGs | Vision globale, backfill simplifiÃ©, plus facile Ã  expliquer |
| Staging TRUNCATE | Staging cumulatif | SimplicitÃ©, rejouabilitÃ©, pas besoin d'historiser |

### 9.3 LeÃ§ons Apprises

1. **Toujours tester en local** avant de dÃ©ployer sur le cluster
2. **Les logs sont essentiels** - Passer de `print()` Ã  `logging` a facilitÃ© le debug
3. **L'idempotence n'est pas optionnelle** - Chaque composant doit Ãªtre rejouable
4. **Docker simplifie mais ajoute de la complexitÃ© rÃ©seau** - Bien comprendre les rÃ©seaux Docker
5. **DÃ©finir les clÃ©s d'unicitÃ© tÃ´t** - Ã‰vite les problÃ¨mes de doublons en production

---

## 10. CONCLUSION ET PERSPECTIVES

### 10.1 Bilan du Projet

Ce projet a permis de construire un **pipeline Big Data complet et fonctionnel**, de la collecte des donnÃ©es jusqu'Ã  la prÃ©diction ML, en passant par le stockage et la visualisation.

**RÃ©alisations principales** :
- âœ… 6 exercices complÃ©tÃ©s et fonctionnels
- âœ… Architecture distribuÃ©e avec Spark (1 master, 2 workers)
- âœ… Data Lake MinIO avec 3 zones (raw, interim, processed prÃ©vu)
- âœ… Data Warehouse PostgreSQL en modÃ¨le Ã©toile
- âœ… ModÃ¨le ML avec **RMSE = 5.17** < 10 (objectif atteint)
- âœ… Orchestration Airflow avec backfill et SLA
- âœ… Infrastructure 100% containerisÃ©e et reproductible

### 10.2 CompÃ©tences Acquises

| Domaine | CompÃ©tences |
|---------|-------------|
| Big Data | Apache Spark, traitement distribuÃ©, partitionnement |
| Data Engineering | ETL, Data Lake, Data Warehouse, modÃ©lisation dimensionnelle |
| MLOps | Model Registry, fenÃªtre glissante, mÃ©triques de qualitÃ© |
| DevOps | Docker, Docker Compose, orchestration |
| Orchestration | Apache Airflow, DAGs, SLA, idempotence |

### 10.3 AmÃ©liorations Possibles et Zone `nyc-processed`

#### Ã‰volutions Court Terme

| PrioritÃ© | AmÃ©lioration | Effort |
|----------|--------------|--------|
| Haute | Alerting Slack/Email en cas d'Ã©chec | 2h |
| Haute | Data drift detection pour le ML | 4h |
| Moyenne | Tests d'intÃ©gration automatisÃ©s | 4h |

#### Exploitation de la Zone Gold (`nyc-processed`)

La zone `nyc-processed` est provisionnÃ©e et prÃªte Ã  Ãªtre utilisÃ©e pour les Ã©volutions suivantes :

| Ã‰volution | Description | BÃ©nÃ©fice |
|-----------|-------------|----------|
| **Batch Scoring** | Ã‰criture des prÃ©dictions ML mensuelles vers `s3a://nyc-processed/predictions/` | Historique des prÃ©dictions, audit trail |
| **AgrÃ©gations prÃ©-calculÃ©es** | KPIs par zone/heure/jour dans `s3a://nyc-processed/aggregates/` | Dashboard temps rÃ©el performant |
| **Features Store** | Features ML versionnÃ©es dans `s3a://nyc-processed/features/` | RÃ©utilisation cross-modÃ¨les, cohÃ©rence |
| **Data Products** | Exports CSV/JSON pour utilisateurs mÃ©tier dans `s3a://nyc-processed/exports/` | Self-service analytics |

**Exemple d'implÃ©mentation future** :
```python
# AprÃ¨s le training ML, sauvegarder les prÃ©dictions
predictions_df.write \
    .mode("overwrite") \
    .partitionBy("year", "month") \
    .parquet("s3a://nyc-processed/predictions/")
```

#### Ã‰volutions Long Terme

| AmÃ©lioration | Effort | Impact |
|--------------|--------|--------|
| Migration vers Kubernetes | 2 jours | ScalabilitÃ© cloud |
| Streaming avec Kafka | 3 jours | Temps rÃ©el |
| Interface Grafana | 1 jour | Monitoring avancÃ© |
| API REST pour prÃ©dictions | 1 jour | IntÃ©gration applicative |

### 10.4 Perspectives

Ce projet constitue une base solide pour :
- Passer Ã  l'Ã©chelle avec Kubernetes et Spark sur K8s
- Ajouter du streaming avec Kafka + Spark Structured Streaming
- DÃ©ployer en production sur le cloud (AWS EMR, GCP Dataproc, Azure Synapse)
- Exploiter pleinement l'architecture Medallion avec la zone Gold

---

## 11. ANNEXES

### A. Structure du Projet

```
nyc-taxi-bigdata-pipeline/
â”œâ”€â”€ docker-compose.yml          # Infrastructure principale
â”œâ”€â”€ .env                        # Variables d'environnement
â”œâ”€â”€ README.md                   # Documentation principale
â”‚
â”œâ”€â”€ Docker/                     # Fichiers Docker
â”‚   â”œâ”€â”€ Dockerfile              # Image Spark
â”‚   â””â”€â”€ Dockerfile.streamlit    # Image Streamlit
â”‚
â”œâ”€â”€ Documents/                  # Documentation et diagrammes
â”‚   â”œâ”€â”€ Project_Architecture.png
â”‚   â””â”€â”€ RAPPORT_PROJET_BIGDATA.pdf
â”‚
â”œâ”€â”€ ex01_data_retrieval/        # EX01 - Collecte donnÃ©es
â”‚   â”œâ”€â”€ src/main/scala/
â”‚   â””â”€â”€ build.sbt
â”‚
â”œâ”€â”€ ex02_data_ingestion/        # EX02 - Nettoyage et ingestion
â”‚   â”œâ”€â”€ src/main/scala/
â”‚   â””â”€â”€ build.sbt
â”‚
â”œâ”€â”€ ex03_sql_table_creation/    # EX03 - Data Warehouse
â”‚   â”œâ”€â”€ dw_creation.sql
â”‚   â””â”€â”€ dw_load_incremental.sql
â”‚
â”œâ”€â”€ ex04_dashboard/             # EX04 - Visualisation
â”‚   â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ streamlit_app/
â”‚
â”œâ”€â”€ ex05_ml_prediction_service/ # EX05 - Machine Learning
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ ml_pipeline.py
â”‚   â”‚   â”œâ”€â”€ trainer.py
â”‚   â”‚   â”œâ”€â”€ logging_config.py   # Logging standardisÃ©
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ tests/
â”‚   â””â”€â”€ reports/
â”‚
â””â”€â”€ ex06_airflow/               # EX06 - Orchestration
    â”œâ”€â”€ dags/
    â”‚   â”œâ”€â”€ full_pipeline_dag.py  # DAG principal
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ tests/
    â”‚   â””â”€â”€ test_dags.py
    â”œâ”€â”€ docker-compose.yml
    â””â”€â”€ README.md
```

### B. Commandes Utiles

```bash
# DÃ©marrer l'infrastructure principale
docker-compose up -d

# VÃ©rifier les services
docker-compose ps

# DÃ©marrer Airflow
cd ex06_airflow
docker-compose up -d

# AccÃ©der aux interfaces
# Spark Master UI  : http://localhost:8081
# MinIO Console    : http://localhost:9001 (minioadmin/minioadmin123)
# Airflow UI       : http://localhost:8080 (airflow/airflow)
# Streamlit        : http://localhost:8501
# PostgreSQL       : localhost:5432 (postgres/postgres)

# Lancer un job Spark manuellement
docker exec spark-master spark-submit \
    --class Ex01DataRetrieval \
    --master spark://spark-master:7077 \
    /opt/workdir/ex01_data_retrieval/target/scala-2.12/ex01-data-retrieval_2.12-0.1.0.jar \
    --year 2023 --month 01

# Lancer le pipeline ML
docker exec spark-master spark-submit \
    --master spark://spark-master:7077 \
    /opt/workdir/ex05_ml_prediction_service/src/ml_pipeline.py \
    --test-month 2023-04 \
    --train-months 2023-01,2023-02,2023-03

# Consulter les logs Airflow
docker-compose logs -f airflow-scheduler

# ExÃ©cuter les tests DAG
cd ex06_airflow
pytest tests/ -v

# ArrÃªter tout
docker-compose down
cd ex06_airflow && docker-compose down
```

### C. Variables d'Environnement

```bash
# .env (racine du projet)
PROJECT_ROOT=S:/PROJECTS/projects/nyc-taxi-bigdata-pipeline
DOCKER_VOLUMES_ROOT=S:/dockervolumes

MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin123

POSTGRES_DB=nyc_taxi
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
```

### D. Buckets MinIO

| Bucket | Zone | Statut | Contenu |
|--------|------|--------|---------|
| `nyc-raw` | Bronze | âœ… Actif | Parquet bruts tÃ©lÃ©chargÃ©s |
| `nyc-interim` | Silver | âœ… Actif | Parquet nettoyÃ©s pour ML |
| `nyc-processed` | Gold | ğŸ”® PrÃ©vu | PrÃ©dictions, agrÃ©gations (futur) |

### E. Liste des Captures d'Ã‰cran Ã  InsÃ©rer

| ID | Section | Description |
|----|---------|-------------|
| CAPTURE_ARCHITECTURE | 2.1 | Documents/Project_Architecture.png |
| CAPTURE_EX01_MINIO | 3.5 | MinIO â†’ nyc-raw/yellow/2023/01/ |
| CAPTURE_EX02_MINIO | 4.5 | MinIO â†’ nyc-interim/yellow/2023/01/ |
| CAPTURE_EX02_STAGING | 4.5 | pgAdmin â†’ COUNT(*) FROM staging |
| CAPTURE_EX03_FACT_COUNT | 5.5 | pgAdmin â†’ COUNT(*) FROM fact_trip |
| CAPTURE_EX03_SCHEMA | 5.5 | pgAdmin â†’ Liste des tables |
| CAPTURE_EX04_DASHBOARD_HOME | 6.4 | Streamlit â†’ Page accueil + KPIs |
| CAPTURE_EX04_DASHBOARD_DISTRIBUTION | 6.4 | Streamlit â†’ Histogramme prix |
| CAPTURE_EX04_DASHBOARD_MAP | 6.4 | Streamlit â†’ Carte/Heatmap zones |
| CAPTURE_EX04_DASHBOARD_TEMPORAL | 6.4 | Streamlit â†’ Graphique par heure |
| CAPTURE_EX04_DASHBOARD_FILTERS | 6.4 | Streamlit â†’ Vue avec filtres |
| CAPTURE_EX05_METRICS | 7.6 | train_metrics.json ou console |
| CAPTURE_EX05_STREAMLIT_ML | 7.6 | Streamlit ML Demo (optionnel) |
| CAPTURE_EX06_DAG_LIST | 8.5 | Airflow â†’ Liste DAGs |
| CAPTURE_EX06_DAG_GRAPH | 8.5 | Airflow â†’ Graph view |
| CAPTURE_EX06_DAG_TREE | 8.5 | Airflow â†’ Tree/Grid view |
| CAPTURE_EX06_TASK_LOG | 8.5 | Airflow â†’ Logs d'une tÃ¢che |

### F. RÃ©fÃ©rences

- NYC TLC Trip Record Data : https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page
- Apache Spark Documentation : https://spark.apache.org/docs/latest/
- Apache Airflow Documentation : https://airflow.apache.org/docs/
- MinIO Documentation : https://min.io/docs/
- PySpark MLlib Guide : https://spark.apache.org/docs/latest/ml-guide.html
- Medallion Architecture : https://www.databricks.com/glossary/medallion-architecture

---

**Fin du rapport**

*Document rÃ©digÃ© dans le cadre du cours Big Data - CY Tech 2024-2025*  
*Rendu : Janvier 2026*